---
title: "Machine Learning Project"
author: "Carlos Ramirez"
date: "May 24, 2018"
output: html_document
---

## **Intro**

The aim of this project was to implement a machine learning technique to predict how well an
exercise activity is performed. Details of the data set can be found [here](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har). 

## **Data preprocessing**

First, the training [data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) was processed and normalized. Since the implementation was focused on accelerometer numeric values
categorical and non-sense variables such as time and user names were dropped. Additionally, column variables filled with NA values and incomplete observations were left apart. Finally, the resulting data was normalized as can be shown next.

```{r message=FALSE,warning=FALSE}
library(caret)
library(dplyr)
library(parallel)
library(doParallel)

## Data preprocessing

## loading train data
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- read.csv(trainURL,colClasses = "character")

processData <- function(data) {
        ## casting data to numeric
        for (i in 1:(ncol(data)-1)) {
                data[,i] <- as.numeric(data[,i])
        }
        
        ## number of NA values for each variable
        NA_number <- sapply(data,function(x) length(which(is.na(x)))) 
        
        ## variables containing too many NA values are allmost constant
        ## hence they could be drop
        ## dropping variables with more than 2/3 of the number of training observations
        drop_vars <- names(data)[NA_number > (2*ncol(data))/3]
        
        ## removing non sense variables as name of the activity subject
        drop_vars <- c(drop_vars,
                       "X","user_name","raw_timestamp_part_1",
                       "raw_timestamp_part_2","cvtd_timestamp",
                       "kurtosis_yaw_belt","skewness_yaw_belt",
                       "kurtosis_yaw_dumbbell","amplitude_yaw_dumbbell",
                       "skewness_yaw_dumbbell","amplitude_yaw_belt",
                       "new_window","num_window")
        data.processed <- data[,!colnames(data)%in%drop_vars]
        #str(data[,colnames(data)%in%drop_vars])
        
        data.processed <- mutate(data.processed,classe=as.factor(classe))
        
        ## droping NA cases
        data.processed <- data.processed[complete.cases(data.processed),]
        
        ## dimension of resulting processed data
        dim(data.processed)
        
        ## normalizing data
        data.stand <- scale(select(data.processed,-classe))
        data.stand <- data.frame(cbind(classe=data.processed$classe,as.data.frame(data.stand)))
        
        return(data.stand)
}

train.stand <- processData(train)
```

Then, a random forest approach was performed on the processed data. Train and test set were defined
as 80 and 20 percent of the total of processed observations, respectively. A 5-fold cross validation
was performed and the number of trees was setted to 45 as shown in the next code. 

```{r}
set.seed(333)

## performing random forest
train <- createDataPartition(train.stand$classe,
                             p = 0.8,
                             list = FALSE)
#tail(train)

fitControl <- trainControl(method = "cv",
                           number = 5)
initialTime <- Sys.time()
forest <- train(classe~.,
                data=train.stand[train,],
                method="rf",
                ntree=45,
                trControl=fitControl)
performanceTime.forest <- Sys.time() - initialTime
#performanceTime.forest

forest.predict <- predict(forest,newdata = train.stand[-train,])
forest.accuracy <- confusionMatrix(forest.predict,train.stand$classe[-train])$overall[1] 
confusionMatrix(forest.predict,train.stand$classe[-train])
```



```{r echo=FALSE,message=FALSE,warning=FALSE}
set.seed(333)

## performing LDA for comparison
train <- createDataPartition(train.stand$classe,
                             p = 0.8,
                             list = FALSE)
#tail(train)

fitControl <- trainControl(method = "cv",
                           number = 5)
initialTime <- Sys.time()
lda <- train(classe~.,
                data=train.stand[train,],
                method="lda",
                trControl=fitControl)
performanceTime.lda <- Sys.time() - initialTime
#performanceTime.lda

lda.predict <- predict(lda,newdata = train.stand[-train,])
lda.accuracy <- confusionMatrix(lda.predict,train.stand$classe[-train])$overall[1]
#lda.accuracy
```


As can be seen from the script and the output the accuracy of the prediction of Random Forest on the
testing data was 0.9926. The performance time was `r performanceTime.forest` seconds. LDA was performed
under the same parameters of training as random forest to compare accuracies in both techniques. 
The accuracy of LDA was `r lda.accuracy` and the time performance was `r performanceTime.lda` seconds.  



## **Random Forest prediction variability**

Samples of size 20 were drawn from the test set in order to evaluate the variability of the accuracy performance of the random forest in samples of this size. In the next plot the values of accuracy for 100 simulations are shown. 

```{r}
## evaluation of random forest accuracy variation

## sampling from test set
total <- 1:nrow(train.stand)
test <- total[!total %in% train]

## performing 100 simulations        
nsims <- 100
accuracy <- numeric(nsims)
for (i in 1:nsims) {
        test20 <- sample(test,20)
        forest.predict <- predict(forest,newdata=train.stand[test20,])
        accuracy[i] <- confusionMatrix(forest.predict,train.stand$classe[test20])$overall[1]  
}

plot(accuracy,type="l",col="steelblue",font.lab=2,lwd=2,
     xlab = "Simulation",ylab = "Accuracy")
```

The mean accuracy value was `r mean(accuracy)` while the standard deviation was `r sd(accuracy)` which suggest it will have good performance for the validation set.

## **Conclusions**

The aim of this report was to implement a machine learning technique to try
predicting how well a body activity is performed. With that goal the body activity data
was carefully processed to keep only numerical values for accelerometers. This approach
allows to implement Random Forest and LDA techniques in reasonable computing time. 
Random Forest had good performance (`r forest.accuracy`). LDA accuracy was poor and only a 
little bit better than a random guest (`r lda.accuracy`).
In order to evaluate the performance of the Random Forest
model in samples with size equal to the validation sample 100 simulations
were carried out on samples of size 20 drawn from the test set. The average accuracy was
`r mean(accuracy)` and the standard deviation was `r sd(accuracy)` which suggest that
the model will perform well in the validation set.

